{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Image Compression Experiments\n",
    "\n",
    "This notebook provides a comprehensive analysis of image compression using Singular Value Decomposition (SVD). We'll explore the trade-offs between compression ratio and image quality across different image types and compression levels.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Loading and Preprocessing](#data-loading)\n",
    "3. [SVD Compression Analysis](#svd-analysis)\n",
    "4. [Quality Metrics Evaluation](#quality-metrics)\n",
    "5. [Visualization and Results](#visualization)\n",
    "6. [Comparative Analysis](#comparative-analysis)\n",
    "7. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}\n",
    "\n",
    "First, let's import all necessary libraries and set up our environment for reproducible experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Our custom modules\n",
    "from compression.svd_compressor import SVDCompressor\n",
    "from data.image_loader import ImageLoader\n",
    "from data.dataset_manager import DatasetManager\n",
    "from evaluation.metrics_calculator import MetricsCalculator\n",
    "from evaluation.performance_profiler import PerformanceProfiler\n",
    "from visualization.plot_generator import PlotGenerator\n",
    "from batch.experiment_runner import ExperimentRunner, ExperimentConfig\n",
    "\n",
    "# Configure warnings and display\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing {#data-loading}\n",
    "\n",
    "Let's load our image datasets and prepare them for compression experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our core components\n",
    "dataset_manager = DatasetManager()\n",
    "image_loader = ImageLoader()\n",
    "compressor = SVDCompressor()\n",
    "metrics_calc = MetricsCalculator()\n",
    "profiler = PerformanceProfiler()\n",
    "plot_gen = PlotGenerator()\n",
    "\n",
    "print(\"âœ… Core components initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and organize datasets\n",
    "print(\"Loading datasets...\")\n",
    "datasets = dataset_manager.load_datasets()\n",
    "\n",
    "print(f\"Available datasets: {list(datasets.keys())}\")\n",
    "for dataset_name, images in datasets.items():\n",
    "    print(f\"  {dataset_name}: {len(images)} images\")\n",
    "\n",
    "# Generate dataset manifest\n",
    "manifest_df = dataset_manager.generate_manifest()\n",
    "print(f\"\\nDataset manifest generated with {len(manifest_df)} entries\")\n",
    "print(manifest_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample image from each dataset for demonstration\n",
    "sample_images = {}\n",
    "sample_paths = {}\n",
    "\n",
    "for dataset_name, image_paths in datasets.items():\n",
    "    if image_paths:  # Check if dataset has images\n",
    "        # Load first image as sample\n",
    "        sample_path = image_paths[0]\n",
    "        sample_image = image_loader.load_image(sample_path)\n",
    "        sample_images[dataset_name] = sample_image\n",
    "        sample_paths[dataset_name] = sample_path\n",
    "        print(f\"Loaded sample from {dataset_name}: {sample_path.name} - Shape: {sample_image.shape}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(sample_images)} sample images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images\n",
    "\n",
    "Let's take a look at our sample images to understand the different types of content we'll be compressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid showing sample images from each dataset\n",
    "if sample_images:\n",
    "    images_list = list(sample_images.values())\n",
    "    titles_list = [f\"{name.title()} Sample\" for name in sample_images.keys()]\n",
    "    \n",
    "    fig = plot_gen.create_image_grid(\n",
    "        images_list, \n",
    "        titles_list,\n",
    "        figsize=(15, 5)\n",
    "    )\n",
    "    plt.suptitle(\"Sample Images from Each Dataset\", fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No sample images available. Please ensure datasets are properly loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVD Compression Analysis {#svd-analysis}\n",
    "\n",
    "Now let's analyze the SVD compression characteristics of our sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze singular value spectra for each sample image\n",
    "singular_value_data = {}\n",
    "\n",
    "for dataset_name, image in sample_images.items():\n",
    "    # Convert to grayscale for singular value analysis\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = np.mean(image, axis=2)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # Get singular value spectrum\n",
    "    singular_values = compressor.singular_value_spectrum(gray_image)\n",
    "    singular_value_data[dataset_name] = singular_values\n",
    "    \n",
    "    print(f\"{dataset_name}: {len(singular_values)} singular values\")\n",
    "    print(f\"  Top 5 values: {singular_values[:5]}\")\n",
    "    print(f\"  Energy in top 10: {np.sum(singular_values[:10]**2) / np.sum(singular_values**2):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot singular value decay for each dataset\n",
    "fig, axes = plt.subplots(1, len(singular_value_data), figsize=(15, 5))\n",
    "if len(singular_value_data) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (dataset_name, sv_data) in enumerate(singular_value_data.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot singular values on log scale\n",
    "    indices = np.arange(1, len(sv_data) + 1)\n",
    "    ax.semilogy(indices, sv_data, 'b-', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Highlight first 50 values\n",
    "    ax.semilogy(indices[:50], sv_data[:50], 'r-', linewidth=3, alpha=0.9)\n",
    "    \n",
    "    ax.set_title(f'{dataset_name.title()} Singular Values', fontweight='bold')\n",
    "    ax.set_xlabel('Singular Value Index')\n",
    "    ax.set_ylabel('Singular Value (log scale)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add annotation for energy concentration\n",
    "    energy_50 = np.sum(sv_data[:50]**2) / np.sum(sv_data**2)\n",
    "    ax.text(0.05, 0.95, f'Energy in top 50: {energy_50:.1%}', \n",
    "            transform=ax.transAxes, fontsize=10, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression Demonstration\n",
    "\n",
    "Let's demonstrate the compression process with different k-values on one sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose first available sample for demonstration\n",
    "demo_dataset = list(sample_images.keys())[0]\n",
    "demo_image = sample_images[demo_dataset]\n",
    "\n",
    "print(f\"Demonstrating compression on {demo_dataset} image\")\n",
    "print(f\"Original image shape: {demo_image.shape}\")\n",
    "\n",
    "# Test different k-values\n",
    "k_values = [5, 15, 30, 60]\n",
    "compressed_images = []\n",
    "compression_info = []\n",
    "\n",
    "# Add original image\n",
    "compressed_images.append(demo_image)\n",
    "titles = ['Original']\n",
    "\n",
    "for k in k_values:\n",
    "    # Compress image\n",
    "    compressed_img, metadata = compressor.compress_image(demo_image, k)\n",
    "    compressed_images.append(compressed_img)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    psnr = metrics_calc.calculate_psnr(demo_image, compressed_img)\n",
    "    ssim = metrics_calc.calculate_ssim(demo_image, compressed_img)\n",
    "    \n",
    "    titles.append(f'k={k}\\nPSNR: {psnr:.1f}dB\\nSSIM: {ssim:.3f}')\n",
    "    compression_info.append({\n",
    "        'k': k,\n",
    "        'psnr': psnr,\n",
    "        'ssim': ssim,\n",
    "        'compression_ratio': metadata['compression_ratio']\n",
    "    })\n",
    "\n",
    "# Display compression results\n",
    "fig = plot_gen.create_image_grid(\n",
    "    compressed_images,\n",
    "    titles,\n",
    "    nrows=1,\n",
    "    figsize=(20, 4)\n",
    ")\n",
    "plt.suptitle(f'SVD Compression Demonstration - {demo_dataset.title()}', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print compression statistics\n",
    "print(\"\\nCompression Statistics:\")\n",
    "for info in compression_info:\n",
    "    print(f\"k={info['k']:2d}: Ratio={info['compression_ratio']:.2f}x, \"\n",
    "          f\"PSNR={info['psnr']:.1f}dB, SSIM={info['ssim']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quality Metrics Evaluation {#quality-metrics}\n",
    "\n",
    "Let's run systematic experiments to evaluate quality metrics across different compression levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment parameters\n",
    "experiment_config = ExperimentConfig(\n",
    "    datasets=list(datasets.keys()),\n",
    "    k_values=list(range(5, 101, 5)),  # k from 5 to 100 in steps of 5\n",
    "    output_dir=Path('../results'),\n",
    "    save_images=False,  # Don't save images in notebook to save space\n",
    "    parallel=True,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Experiment configuration:\")\n",
    "print(f\"  Datasets: {experiment_config.datasets}\")\n",
    "print(f\"  K-values: {len(experiment_config.k_values)} values from {min(experiment_config.k_values)} to {max(experiment_config.k_values)}\")\n",
    "print(f\"  Output directory: {experiment_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch experiments\n",
    "print(\"Running batch experiments...\")\n",
    "print(\"This may take a few minutes depending on the number of images and k-values.\")\n",
    "\n",
    "experiment_runner = ExperimentRunner()\n",
    "results_df = experiment_runner.run_batch_experiments(experiment_config)\n",
    "\n",
    "print(f\"\\nâœ… Experiments completed!\")\n",
    "print(f\"Generated {len(results_df)} result records\")\n",
    "print(f\"\\nResults summary:\")\n",
    "print(results_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results\n",
    "print(\"Sample results:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "print(\"\\nResults by dataset:\")\n",
    "print(results_df.groupby('dataset').agg({\n",
    "    'psnr': ['mean', 'std'],\n",
    "    'ssim': ['mean', 'std'],\n",
    "    'compression_ratio': ['mean', 'std']\n",
    "}).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and Results {#visualization}\n",
    "\n",
    "Now let's create comprehensive visualizations of our experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PSNR vs k-value for all datasets\n",
    "fig = plot_gen.plot_quality_vs_k(\n",
    "    results_df, \n",
    "    metric='psnr',\n",
    "    save_path=Path('../results/plots/psnr_vs_k_notebook.png')\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot SSIM vs k-value for all datasets\n",
    "fig = plot_gen.plot_quality_vs_k(\n",
    "    results_df, \n",
    "    metric='ssim',\n",
    "    save_path=Path('../results/plots/ssim_vs_k_notebook.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compression analysis scatter plots\n",
    "fig = plot_gen.plot_compression_analysis(\n",
    "    results_df,\n",
    "    quality_metric='psnr',\n",
    "    save_path=Path('../results/plots/compression_vs_psnr_notebook.png')\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "fig = plot_gen.plot_compression_analysis(\n",
    "    results_df,\n",
    "    quality_metric='ssim',\n",
    "    save_path=Path('../results/plots/compression_vs_ssim_notebook.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-metric comparison plot\n",
    "fig = plot_gen.plot_multiple_metrics(\n",
    "    results_df,\n",
    "    metrics=['psnr', 'ssim'],\n",
    "    save_path=Path('../results/plots/multi_metrics_notebook.png')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "\n",
    "Let's analyze the computational performance of our compression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze processing times\n",
    "if 'processing_time' in results_df.columns:\n",
    "    print(\"Processing Time Analysis:\")\n",
    "    print(f\"Mean processing time: {results_df['processing_time'].mean():.4f} seconds\")\n",
    "    print(f\"Std processing time: {results_df['processing_time'].std():.4f} seconds\")\n",
    "    \n",
    "    # Plot processing time vs k-value\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for dataset in results_df['dataset'].unique():\n",
    "        dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "        grouped = dataset_data.groupby('k_value')['processing_time'].mean().reset_index()\n",
    "        \n",
    "        ax.plot(grouped['k_value'], grouped['processing_time'], \n",
    "                marker='o', label=dataset.title(), linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Number of Singular Values (k)')\n",
    "    ax.set_ylabel('Processing Time (seconds)')\n",
    "    ax.set_title('Processing Time vs k-value', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Processing time data not available in results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparative Analysis {#comparative-analysis}\n",
    "\n",
    "Let's perform detailed comparative analysis across different image types and compression levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal k-values for different quality thresholds\n",
    "quality_thresholds = {\n",
    "    'High Quality': {'psnr_min': 30, 'ssim_min': 0.9},\n",
    "    'Medium Quality': {'psnr_min': 25, 'ssim_min': 0.8},\n",
    "    'Low Quality': {'psnr_min': 20, 'ssim_min': 0.7}\n",
    "}\n",
    "\n",
    "optimal_k_analysis = {}\n",
    "\n",
    "for quality_level, thresholds in quality_thresholds.items():\n",
    "    print(f\"\\n{quality_level} Analysis (PSNR â‰¥ {thresholds['psnr_min']}dB, SSIM â‰¥ {thresholds['ssim_min']}):\")\n",
    "    \n",
    "    for dataset in results_df['dataset'].unique():\n",
    "        dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "        \n",
    "        # Filter by quality thresholds\n",
    "        quality_data = dataset_data[\n",
    "            (dataset_data['psnr'] >= thresholds['psnr_min']) & \n",
    "            (dataset_data['ssim'] >= thresholds['ssim_min'])\n",
    "        ]\n",
    "        \n",
    "        if len(quality_data) > 0:\n",
    "            # Find minimum k that meets quality requirements\n",
    "            min_k = quality_data['k_value'].min()\n",
    "            optimal_row = quality_data[quality_data['k_value'] == min_k].iloc[0]\n",
    "            \n",
    "            print(f\"  {dataset}: k={min_k}, \"\n",
    "                  f\"PSNR={optimal_row['psnr']:.1f}dB, \"\n",
    "                  f\"SSIM={optimal_row['ssim']:.3f}, \"\n",
    "                  f\"Ratio={optimal_row['compression_ratio']:.2f}x\")\n",
    "            \n",
    "            optimal_k_analysis[f\"{quality_level}_{dataset}\"] = {\n",
    "                'k': min_k,\n",
    "                'psnr': optimal_row['psnr'],\n",
    "                'ssim': optimal_row['ssim'],\n",
    "                'compression_ratio': optimal_row['compression_ratio']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"  {dataset}: No k-value meets quality requirements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics table\n",
    "summary_stats = results_df.groupby(['dataset', 'k_value']).agg({\n",
    "    'psnr': ['mean', 'std'],\n",
    "    'ssim': ['mean', 'std'],\n",
    "    'compression_ratio': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"Summary Statistics by Dataset and K-value:\")\n",
    "print(summary_stats.head(15))\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_path = Path('../results/summary_statistics_notebook.csv')\n",
    "summary_stats.to_csv(summary_path)\n",
    "print(f\"\\nðŸ“Š Summary statistics saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between metrics\n",
    "correlation_matrix = results_df[['k_value', 'psnr', 'ssim', 'mse', 'compression_ratio']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Compression Metrics', fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Correlations:\")\n",
    "print(f\"k_value vs PSNR: {correlation_matrix.loc['k_value', 'psnr']:.3f}\")\n",
    "print(f\"k_value vs SSIM: {correlation_matrix.loc['k_value', 'ssim']:.3f}\")\n",
    "print(f\"PSNR vs SSIM: {correlation_matrix.loc['psnr', 'ssim']:.3f}\")\n",
    "print(f\"Compression Ratio vs PSNR: {correlation_matrix.loc['compression_ratio', 'psnr']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions {#conclusions}\n",
    "\n",
    "Based on our comprehensive analysis of SVD image compression, we can draw several important conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate automated conclusions based on results\n",
    "print(\"ðŸ“‹ EXPERIMENTAL CONCLUSIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall performance summary\n",
    "overall_stats = results_df.groupby('k_value').agg({\n",
    "    'psnr': 'mean',\n",
    "    'ssim': 'mean',\n",
    "    'compression_ratio': 'mean'\n",
    "})\n",
    "\n",
    "# Find sweet spot k-values\n",
    "good_quality_k = overall_stats[(overall_stats['psnr'] >= 30) & (overall_stats['ssim'] >= 0.85)]\n",
    "if len(good_quality_k) > 0:\n",
    "    optimal_k = good_quality_k.index.min()\n",
    "    print(f\"\\n1. OPTIMAL COMPRESSION LEVEL:\")\n",
    "    print(f\"   k = {optimal_k} provides good quality (PSNR â‰¥ 30dB, SSIM â‰¥ 0.85)\")\n",
    "    print(f\"   at this level: PSNR = {good_quality_k.loc[optimal_k, 'psnr']:.1f}dB, \"\n",
    "          f\"SSIM = {good_quality_k.loc[optimal_k, 'ssim']:.3f}\")\n",
    "\n",
    "# Dataset comparison\n",
    "dataset_performance = results_df.groupby('dataset').agg({\n",
    "    'psnr': 'mean',\n",
    "    'ssim': 'mean',\n",
    "    'compression_ratio': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "best_dataset = dataset_performance['psnr'].idxmax()\n",
    "worst_dataset = dataset_performance['psnr'].idxmin()\n",
    "\n",
    "print(f\"\\n2. DATASET PERFORMANCE:\")\n",
    "print(f\"   Best performing: {best_dataset} (avg PSNR: {dataset_performance.loc[best_dataset, 'psnr']:.1f}dB)\")\n",
    "print(f\"   Most challenging: {worst_dataset} (avg PSNR: {dataset_performance.loc[worst_dataset, 'psnr']:.1f}dB)\")\n",
    "\n",
    "# Compression efficiency\n",
    "high_compression = results_df[results_df['compression_ratio'] >= 5.0]\n",
    "if len(high_compression) > 0:\n",
    "    avg_quality_high_comp = high_compression['psnr'].mean()\n",
    "    print(f\"\\n3. COMPRESSION EFFICIENCY:\")\n",
    "    print(f\"   At 5x+ compression: average PSNR = {avg_quality_high_comp:.1f}dB\")\n",
    "    print(f\"   High compression achievable with acceptable quality loss\")\n",
    "\n",
    "# Key findings\n",
    "print(f\"\\n4. KEY FINDINGS:\")\n",
    "print(f\"   â€¢ SVD compression shows strong correlation between k and quality\")\n",
    "print(f\"   â€¢ PSNR and SSIM are highly correlated (r = {correlation_matrix.loc['psnr', 'ssim']:.3f})\")\n",
    "print(f\"   â€¢ Different image types show varying compression characteristics\")\n",
    "print(f\"   â€¢ Energy concentration in top singular values enables effective compression\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATIONS:\")\n",
    "print(f\"   â€¢ For high quality: use k â‰¥ {optimal_k if 'optimal_k' in locals() else 50}\")\n",
    "print(f\"   â€¢ For balanced compression: k = 20-40 range provides good trade-offs\")\n",
    "print(f\"   â€¢ Consider image content type when selecting compression parameters\")\n",
    "print(f\"   â€¢ Monitor both PSNR and SSIM for comprehensive quality assessment\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"âœ… Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results and Plots\n",
    "\n",
    "Finally, let's save our results and generated plots for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete results DataFrame\n",
    "results_path = Path('../results/notebook_experiment_results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"ðŸ“Š Complete results saved to {results_path}\")\n",
    "\n",
    "# Save optimal k analysis\n",
    "if optimal_k_analysis:\n",
    "    optimal_df = pd.DataFrame(optimal_k_analysis).T\n",
    "    optimal_path = Path('../results/optimal_k_analysis.csv')\n",
    "    optimal_df.to_csv(optimal_path)\n",
    "    print(f\"ðŸŽ¯ Optimal k analysis saved to {optimal_path}\")\n",
    "\n",
    "# Create a final summary plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: PSNR vs k\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "    grouped = dataset_data.groupby('k_value')['psnr'].mean().reset_index()\n",
    "    ax1.plot(grouped['k_value'], grouped['psnr'], marker='o', label=dataset.title())\n",
    "ax1.set_xlabel('k-value')\n",
    "ax1.set_ylabel('PSNR (dB)')\n",
    "ax1.set_title('PSNR vs k-value')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: SSIM vs k\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "    grouped = dataset_data.groupby('k_value')['ssim'].mean().reset_index()\n",
    "    ax2.plot(grouped['k_value'], grouped['ssim'], marker='o', label=dataset.title())\n",
    "ax2.set_xlabel('k-value')\n",
    "ax2.set_ylabel('SSIM')\n",
    "ax2.set_title('SSIM vs k-value')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Compression ratio vs PSNR\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    dataset_data = results_df[results_df['dataset'] == dataset]\n",
    "    ax3.scatter(dataset_data['compression_ratio'], dataset_data['psnr'], \n",
    "               alpha=0.6, label=dataset.title())\n",
    "ax3.set_xlabel('Compression Ratio')\n",
    "ax3.set_ylabel('PSNR (dB)')\n",
    "ax3.set_title('Compression Ratio vs PSNR')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Dataset performance comparison\n",
    "dataset_means = results_df.groupby('dataset')[['psnr', 'ssim']].mean()\n",
    "x_pos = np.arange(len(dataset_means))\n",
    "width = 0.35\n",
    "\n",
    "ax4.bar(x_pos - width/2, dataset_means['psnr'], width, label='PSNR', alpha=0.8)\n",
    "ax4_twin = ax4.twinx()\n",
    "ax4_twin.bar(x_pos + width/2, dataset_means['ssim'], width, \n",
    "             label='SSIM', alpha=0.8, color='orange')\n",
    "\n",
    "ax4.set_xlabel('Dataset')\n",
    "ax4.set_ylabel('PSNR (dB)', color='blue')\n",
    "ax4_twin.set_ylabel('SSIM', color='orange')\n",
    "ax4.set_title('Average Performance by Dataset')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels([d.title() for d in dataset_means.index])\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('SVD Image Compression - Complete Analysis Summary', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save summary plot\n",
    "summary_plot_path = Path('../results/plots/complete_analysis_summary.png')\n",
    "plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“ˆ Summary plot saved to {summary_plot_path}\")\n",
    "print(\"\\nðŸŽ‰ Notebook analysis complete! All results and plots have been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "This notebook has provided a comprehensive analysis of SVD image compression, including:\n",
    "\n",
    "1. **Data Loading**: Systematic loading and preprocessing of image datasets\n",
    "2. **SVD Analysis**: Examination of singular value spectra and energy concentration\n",
    "3. **Compression Demonstration**: Visual comparison of different compression levels\n",
    "4. **Quality Evaluation**: Systematic measurement of PSNR, SSIM, and other metrics\n",
    "5. **Performance Analysis**: Computational efficiency and processing time evaluation\n",
    "6. **Comparative Study**: Cross-dataset analysis and optimal parameter identification\n",
    "7. **Results Visualization**: Professional plots and statistical summaries\n",
    "\n",
    "The results demonstrate that SVD provides an effective method for image compression with tunable quality-compression trade-offs. The analysis shows clear relationships between the number of singular values retained (k) and resulting image quality, with different image types showing varying compression characteristics.\n",
    "\n",
    "All results, plots, and analysis summaries have been saved to the `results/` directory for further use and presentation.\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook was generated as part of the SVD Image Compression project. For more information, see the project documentation and source code.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}